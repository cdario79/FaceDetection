{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5IMirWvw9kvn5q3t3UdV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdario79/FaceDetection/blob/main/Face_Detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Detection per Fotocamere Digitali"
      ],
      "metadata": {
        "id": "mu3vnxUIND8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descrizione e motivazioni della soluzione adottata\n",
        "\n",
        "Il progetto consiste nella realizzazione di un sistema di **Face Detection** interamente costruito da zero, destinato allâ€™integrazione in una nuova fotocamera digitale compatta.  \n",
        "Lâ€™obiettivo Ã¨ rilevare automaticamente i volti nelle immagini (soprattutto selfie con piÃ¹ persone), restituendo i bounding box corrispondenti per supportare lâ€™ottimizzazione automatica delle impostazioni di scatto.\n",
        "\n",
        "Il progetto presenta vincoli molto specifici:\n",
        "\n",
        "- Non Ã¨ consentito lâ€™utilizzo di **modelli pre-addestrati**\n",
        "- Non viene fornito **alcun dataset** predefinito\n",
        "- Il sistema deve funzionare con **risorse computazionali limitate**\n",
        "- Ãˆ richiesto du usare **Scikit-learn** per lâ€™addestramento del modello\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "### Processo di analisi e ricerca\n",
        "\n",
        "Partendo da questi vincoli, ho escluso fin da subito le soluzioni basate su deep learning, come **YOLO**, **MTCNN**, **RetinaFace** o **ResNet-based detectors**, in quanto si basano su modelli pre-addestrati e richiedono risorse computazionali e librerie non compatibili (es. TensorFlow o PyTorch).  \n",
        "Anche **Viola-Jones**, seppur un metodo classico, Ã¨ stato escluso perchÃ© in OpenCV Ã¨ distribuito come modello XML pre-addestrato non compatibile con le restrizioni del progetto.\n",
        "\n",
        "La prima fase di ricerca Ã¨ partita su Google e su siti tecnici come Medium, Towards Data Science, StackOverflow e PyImageSearch, da cui ho ottenuto questi risultati:\n",
        "\n",
        "-  ðŸ”— [PyImageSearch â€“ Face Detection with HOG + SVM](https://pyimagesearch.com/2015/05/04/basic-motion-detection-and-tracking-with-python-and-opencv/)  \n",
        "- ðŸ”— [Towards Data Science â€“ Before Deep Learning: Classical Face Detection](https://towardsdatascience.com/face-detection-methods-before-deep-learning-5c0be2d75057)\n",
        "\n",
        "Queste ricerche mi hanno aiutato a identificare tre approcci classici utilizzabili:\n",
        "\n",
        "1. **Haar-like features + Adaboost (Viola-Jones)** â€“ scartato per il motivo giÃ  citato.\n",
        "2. **LBP (Local Binary Pattern)** â€“ semplice e veloce, ma meno efficace.\n",
        "3. **HOG (Histogram of Oriented Gradients) + SVM** â€“ metodo efficace e compatibile con Scikit-learn.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "#### Approfondimento HOG + SVM\n",
        "\n",
        "Ho approfondito **HOG** partendo dal paper originale:\n",
        "\n",
        "- **Dalal & Triggs (2005)**  \n",
        "  ðŸ”— [PDF](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)\n",
        "\n",
        "e la sua implementazione con `scikit-image`, che permette lâ€™estrazione delle feature in modo semplice e veloce.  \n",
        "Per la classificazione, ho scelto **SVM**, facilmente gestibile con `scikit-learn`, giÃ  usato in precedenti progetti ML e adatto a task binari come \"face / non-face\".\n",
        "\n",
        "Inoltre, il sito PyImageSearch Ã¨ stato molto utile per comprendere lâ€™implementazione manuale di tecniche come:\n",
        "\n",
        "- **Sliding Window**  \n",
        "- **Non-Maximum Suppression (NMS)**  \n",
        "- **Valutazione con TP/FP/FN**  \n",
        "ðŸ”— [https://pyimagesearch.com](https://pyimagesearch.com)\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "### Soluzione finale adottata: HOG + SVM + Sliding Window\n",
        "\n",
        "Alla luce di queste considerazioni, ho progettato una pipeline interamente personalizzata che soddisfa tutti i requisiti del progetto:\n",
        "\n",
        "1. **Estrazione delle feature HOG** tramite `skimage.feature.hog`\n",
        "2. **Classificatore SVM** (`sklearn.svm.SVC`) addestrato da zero su patch positive/negative\n",
        "3. **Sliding Window** per scansionare lâ€™immagine in fase di predizione\n",
        "4. **Non-Maximum Suppression** per eliminare sovrapposizioni\n",
        "5. **Visualizzazione finale** con codifica dei bounding box:\n",
        "   - Verde = True Positive\n",
        "   - Rosso = False Positive\n",
        "   - Giallo = False Negative\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "### Dataset utilizzato\n",
        "\n",
        "PoichÃ© il progetto non fornisce un dataset, ho costruito il dataset in autonomia:\n",
        "\n",
        "- **Positive (volti)**: scaricati dal dataset **Labeled Faces in the Wild (LFW)**  \n",
        "  ðŸ”— [http://vis-www.cs.umass.edu/lfw/](http://vis-www.cs.umass.edu/lfw/)\n",
        "- **Negative (non-volti)**: estratti da immagini generiche del dataset **Caltech 101**, evitando categorie con volti o animali  \n",
        "  ðŸ”— [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n",
        "- Le annotazioni per le immagini di test sono state create manualmente in formato **Pascal VOC (XML)** usando [LabelImg](https://github.com/tzutalin/labelImg)"
      ],
      "metadata": {
        "id": "h00iQ900NDrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIPENDENZE"
      ],
      "metadata": {
        "id": "G2pRoJGRI16P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8friuAIJHuv-"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn scikit-image pillow matplotlib numpy lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTAZIONE LIBRERIE"
      ],
      "metadata": {
        "id": "5e-36kY7JHC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerie standard\n",
        "import os\n",
        "import shutil\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "import random\n",
        "\n",
        "# Librerie scientifiche\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Elaborazione immagini\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Scikit-image\n",
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "R-FMb2T-JLOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FUNZIONI UTILIZZATE"
      ],
      "metadata": {
        "id": "279W_wTKI8Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_negative_images(\n",
        "    categories=None,\n",
        "    output_dir=\"dataset/negative\",\n",
        "    image_size=(64, 64),\n",
        "    num_images=500,\n",
        "    seed=42\n",
        "):\n",
        "    # Percorsi temporanei\n",
        "    zip_path = \"caltech101.zip\"\n",
        "    temp_dir = \"caltech101\"\n",
        "    tar_subdir = os.path.join(temp_dir, \"caltech-101\")\n",
        "    tar_path = os.path.join(tar_subdir, \"101_ObjectCategories.tar.gz\")\n",
        "    raw_extract_dir = \"raw/negative\"\n",
        "    extract_dir = os.path.join(raw_extract_dir, \"101_ObjectCategories\")\n",
        "\n",
        "    # Scarica lo ZIP\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(\"ðŸ“¥ Downloading Caltech101 ZIP...\")\n",
        "    urllib.request.urlretrieve(\n",
        "        \"https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip?download=1\",\n",
        "        zip_path\n",
        "    )\n",
        "\n",
        "    print(\"ðŸ“¦ Extracting ZIP...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "    if not os.path.exists(tar_path):\n",
        "        print(\"âŒ File .tar.gz non trovato dopo unzip!\")\n",
        "        return\n",
        "\n",
        "    print(\"ðŸ“¦ Extracting .tar.gz to:\", extract_dir)\n",
        "    os.makedirs(raw_extract_dir, exist_ok=True)\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar_ref:\n",
        "        tar_ref.extractall(raw_extract_dir)\n",
        "\n",
        "    # Cleanup zip e cartella temporanea\n",
        "    os.remove(zip_path)\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(\"ðŸ§¹ Pulizia ZIP e cartella temporanea completata.\")\n",
        "\n",
        "    # Estrazione immagini negative\n",
        "    print(\"ðŸ–¼ Estrazione immagini negative...\")\n",
        "    if categories is None:\n",
        "        categories = ['accordion', 'camera', 'airplanes', 'scissors', 'helicopter', 'chair', 'umbrella']\n",
        "\n",
        "    all_paths = []\n",
        "    random.seed(seed)\n",
        "\n",
        "    for cat in categories:\n",
        "        cat_path = os.path.join(extract_dir, cat)\n",
        "        if not os.path.exists(cat_path):\n",
        "            print(f\"[!] Categoria non trovata: {cat}\")\n",
        "            continue\n",
        "        files = [os.path.join(cat_path, f) for f in os.listdir(cat_path) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
        "        all_paths.extend(files)\n",
        "\n",
        "    if not all_paths:\n",
        "        print(\"âŒ Nessuna immagine trovata.\")\n",
        "        return\n",
        "\n",
        "    selected = random.sample(all_paths, min(num_images, len(all_paths)))\n",
        "\n",
        "    count = 0\n",
        "    for path in selected:\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "            img = img.resize(image_size)\n",
        "            save_path = os.path.join(output_dir, f\"nonface_{count}.jpg\")\n",
        "            if not os.path.exists(save_path):\n",
        "                img.save(save_path)\n",
        "                count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"[x] Errore con {path}: {e}\")\n",
        "\n",
        "    print(f\"[âœ…] Salvate {count} immagini negative in {output_dir}\")\n",
        "\n",
        "    # Elimina la cartella raw dopo la copia\n",
        "    if os.path.exists(raw_extract_dir):\n",
        "        shutil.rmtree(raw_extract_dir)\n",
        "        print(\"ðŸ§¹ Cartella 'raw/negative' eliminata.\")"
      ],
      "metadata": {
        "id": "RmAZ8IiyVUzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_positive_images(\n",
        "    output_dir=\"dataset/positive\",\n",
        "    image_size=(64, 64),\n",
        "    num_images=500,\n",
        "    seed=42\n",
        "):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    random.seed(seed)\n",
        "\n",
        "    print(\"ðŸ“¥ Caricamento del dataset LFW...\")\n",
        "    lfw = fetch_lfw_people(color=True, resize=1.0)\n",
        "    images = lfw.images  # shape: (n_samples, height, width, 3)\n",
        "\n",
        "    total_available = len(images)\n",
        "    print(f\"ðŸ“Š Totale immagini disponibili: {total_available}\")\n",
        "\n",
        "    if total_available == 0:\n",
        "        print(\"âŒ Nessuna immagine disponibile nel dataset.\")\n",
        "        return\n",
        "\n",
        "    indices = list(range(total_available))\n",
        "    random.shuffle(indices)\n",
        "    selected = indices[:min(num_images, total_available)]\n",
        "\n",
        "    count = 0\n",
        "    for i in selected:\n",
        "        try:\n",
        "            # Converti immagine float (0-1) a uint8 (0-255)\n",
        "            img_array = (images[i] * 255).astype(np.uint8)\n",
        "            img = Image.fromarray(img_array)\n",
        "            img = img.resize(image_size)\n",
        "            save_path = os.path.join(output_dir, f\"face_{count}.jpg\")\n",
        "            if not os.path.exists(save_path):\n",
        "                img.save(save_path)\n",
        "                count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"[x] Errore con immagine {i}: {e}\")\n",
        "\n",
        "    print(f\"[âœ…] Salvate {count} immagini di volti in {output_dir}\")"
      ],
      "metadata": {
        "id": "ygkYoWY_THPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hog_features(img_np, size=(64, 64)):\n",
        "    img_resized = resize(img_np, size, anti_aliasing=True)\n",
        "    gray = rgb2gray(img_resized)\n",
        "    features = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
        "    return features"
      ],
      "metadata": {
        "id": "d22kUsJsJEve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window(image_np, window_size=(64, 64), step=16):\n",
        "    h, w, _ = image_np.shape\n",
        "    for y in range(0, h - window_size[1], step):\n",
        "        for x in range(0, w - window_size[0], step):\n",
        "            window = image_np[y:y+window_size[1], x:x+window_size[0]]\n",
        "            yield (x, y, window)"
      ],
      "metadata": {
        "id": "L9YMhvHnJPAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression(boxes, overlap_thresh=0.3):\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    boxes = np.array(boxes)\n",
        "    x1 = boxes[:,0]\n",
        "    y1 = boxes[:,1]\n",
        "    x2 = boxes[:,0] + boxes[:,2]\n",
        "    y2 = boxes[:,1] + boxes[:,3]\n",
        "    scores = boxes[:,4]\n",
        "\n",
        "    idxs = np.argsort(scores)\n",
        "    pick = []\n",
        "\n",
        "    while len(idxs) > 0:\n",
        "        last = idxs[-1]\n",
        "        pick.append(last)\n",
        "        suppress = [last]\n",
        "        for i in idxs[:-1]:\n",
        "            xx1 = max(x1[last], x1[i])\n",
        "            yy1 = max(y1[last], y1[i])\n",
        "            xx2 = min(x2[last], x2[i])\n",
        "            yy2 = min(y2[last], y2[i])\n",
        "\n",
        "            w = max(0, xx2 - xx1)\n",
        "            h = max(0, yy2 - yy1)\n",
        "            overlap = float(w * h) / ((x2[i] - x1[i]) * (y2[i] - y1[i]))\n",
        "            if overlap > overlap_thresh:\n",
        "                suppress.append(i)\n",
        "\n",
        "        idxs = np.delete(idxs, [np.where(idxs == s)[0][0] for s in suppress])\n",
        "\n",
        "    return boxes[pick].astype(int)"
      ],
      "metadata": {
        "id": "nudB5cPDJQ32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_faces_pillow(image_path, clf, window_size=(64, 64), step=16, threshold=0.6):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_np = np.array(img)\n",
        "    detections = []\n",
        "\n",
        "    for (x, y, window) in sliding_window(img_np, window_size, step):\n",
        "        if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
        "            continue\n",
        "        features = extract_hog_features(window)\n",
        "        proba = clf.predict_proba([features])[0][1]\n",
        "        if proba > threshold:\n",
        "            detections.append([x, y, window_size[0], window_size[1], proba])\n",
        "\n",
        "    return non_max_suppression(detections)"
      ],
      "metadata": {
        "id": "S1Wes_HoJTYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
        "    return iou"
      ],
      "metadata": {
        "id": "SeVxailnJZgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_annotations(xml_path):\n",
        "    import xml.etree.ElementTree as ET\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    for obj in root.findall(\"object\"):\n",
        "        box = obj.find(\"bndbox\")\n",
        "        x1 = int(box.find(\"xmin\").text)\n",
        "        y1 = int(box.find(\"ymin\").text)\n",
        "        x2 = int(box.find(\"xmax\").text)\n",
        "        y2 = int(box.find(\"ymax\").text)\n",
        "        boxes.append([x1, y1, x2, y2])\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "DFHxDQeJJbYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizza_risultati(image_path, annot_path, clf, iou_thresh=0.3):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    gt_boxes = parse_annotations(annot_path)\n",
        "    pred_boxes = detect_faces_pillow(image_path, clf)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    matched_gt = set()\n",
        "\n",
        "    for pb in pred_boxes:\n",
        "        pb_box = [pb[0], pb[1], pb[0] + pb[2], pb[1] + pb[3]]\n",
        "        matched = False\n",
        "        for i, gt in enumerate(gt_boxes):\n",
        "            iou = compute_iou(pb_box, gt)\n",
        "            if iou >= iou_thresh and i not in matched_gt:\n",
        "                matched_gt.add(i)\n",
        "                draw.rectangle(pb_box, outline=\"green\", width=2)  # TP\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            draw.rectangle(pb_box, outline=\"red\", width=2)  # FP\n",
        "\n",
        "    for i, gt in enumerate(gt_boxes):\n",
        "        if i not in matched_gt:\n",
        "            draw.rectangle(gt, outline=\"yellow\", width=2)  # FN\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"TP=verde, FP=rosso, FN=giallo\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "h9Zd5RWMJdN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(pos_dir, neg_dir, size=(64, 64)):\n",
        "    X, y = [], []\n",
        "    for fname in os.listdir(pos_dir):\n",
        "        path = os.path.join(pos_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        X.append(extract_hog_features(np.array(img), size))\n",
        "        y.append(1)\n",
        "    for fname in os.listdir(neg_dir):\n",
        "        path = os.path.join(neg_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        X.append(extract_hog_features(np.array(img), size))\n",
        "        y.append(0)\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "NuvP88qqJuU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_batch(test_images_dir, annotations_dir, clf, iou_thresh=0.3):\n",
        "    total_TP, total_FP, total_FN = 0, 0, 0\n",
        "    for fname in os.listdir(test_images_dir):\n",
        "        if not fname.endswith(\".jpg\"): continue\n",
        "        img_path = os.path.join(test_images_dir, fname)\n",
        "        annot_path = os.path.join(annotations_dir, fname.replace(\".jpg\", \".xml\"))\n",
        "        if not os.path.exists(annot_path): continue\n",
        "\n",
        "        gt = parse_annotations(annot_path)\n",
        "        pred = detect_faces_pillow(img_path, clf)\n",
        "        TP, FP, FN = 0, 0, 0\n",
        "        matched_gt = set()\n",
        "\n",
        "        for pb in pred:\n",
        "            pb_box = [pb[0], pb[1], pb[0]+pb[2], pb[1]+pb[3]]\n",
        "            matched = False\n",
        "            for i, gt_box in enumerate(gt):\n",
        "                if i in matched_gt: continue\n",
        "                iou = compute_iou(pb_box, gt_box)\n",
        "                if iou >= iou_thresh:\n",
        "                    TP += 1\n",
        "                    matched_gt.add(i)\n",
        "                    matched = True\n",
        "                    break\n",
        "            if not matched: FP += 1\n",
        "        FN = len(gt) - TP\n",
        "        total_TP += TP\n",
        "        total_FP += FP\n",
        "        total_FN += FN\n",
        "\n",
        "    precision = total_TP / (total_TP + total_FP + 1e-6)\n",
        "    recall = total_TP / (total_TP + total_FN + 1e-6)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
        "\n",
        "    print(\"=== Valutazione finale ===\")\n",
        "    print(f\"TP: {total_TP}, FP: {total_FP}, FN: {total_FN}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "P68LXm6RKQ3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREAZIONE DEL DATASET"
      ],
      "metadata": {
        "id": "0HUzdlfPToNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_and_extract_negative_images(\n",
        "    output_dir=\"dataset/negative\",\n",
        "    image_size=(64, 64),\n",
        "    num_images=500,\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WSaBxW2VZ5O",
        "outputId": "dd019342-1f48-4176-a29a-498263992aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading Caltech101 ZIP...\n",
            "ðŸ“¦ Extracting ZIP...\n",
            "ðŸ“¦ Extracting .tar.gz to: raw/negative/101_ObjectCategories\n",
            "ðŸ§¹ Pulizia ZIP e cartella temporanea completata.\n",
            "ðŸ–¼ Estrazione immagini negative...\n",
            "[âœ…] Salvate 500 immagini negative in dataset/negative\n",
            "ðŸ§¹ Cartella 'raw/negative' eliminata.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_and_extract_positive_images(\n",
        "    output_dir=\"dataset/positive\",\n",
        "    image_size=(64, 64),\n",
        "    num_images=500,\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVGIwb_EWzjb",
        "outputId": "60b47a97-c8a6-45dc-c66d-3349193dd3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Caricamento del dataset LFW...\n",
            "ðŸ“Š Totale immagini disponibili: 13233\n",
            "[âœ…] Salvate 500 immagini di volti in dataset/positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPARAZIONE DEL DATASET"
      ],
      "metadata": {
        "id": "8cqa5iT_JjqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_dir = \"/content/dataset/positive\"\n",
        "negative_dir = \"/content/dataset/negative\"\n",
        "\n",
        "X, y = load_dataset(positive_dir, negative_dir)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3BnWIbWDJvNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADDESTRAMENTO DEL CLASSIFICATORE SVM"
      ],
      "metadata": {
        "id": "qt9i99nZJ5qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(probability=True, kernel='rbf')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Modello addestrato con successo!\")"
      ],
      "metadata": {
        "id": "-jGop7HkJ8Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST SU UN'IMMAGINE REALE"
      ],
      "metadata": {
        "id": "FqOa6KQdJ_d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esempio immagine test con annotation XML\n",
        "test_image = \"/content/test_images/img_001.jpg\"\n",
        "test_annot = \"/content/test_annotations/img_001.xml\"\n",
        "\n",
        "boxes = detect_faces_pillow(test_image, clf)\n",
        "print(f\"Rilevati {len(boxes)} volti\")"
      ],
      "metadata": {
        "id": "E8PxkLhgKBe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valutazione e risultati\n",
        "\n",
        "Il modello Ã¨ stato testato su immagini annotate manualmente. Sono state calcolate le metriche fondamentali:\n",
        "\n",
        "- **Precision** â†’ accuratezza dei rilevamenti positivi\n",
        "- **Recall** â†’ copertura dei volti effettivamente presenti\n",
        "- **F1-score** â†’ bilanciamento tra precision e recall\n",
        "\n",
        "I risultati ottenuti sono stati piÃ¹ che soddisfacenti, considerando la semplicitÃ  dellâ€™architettura e lâ€™assenza di deep learning."
      ],
      "metadata": {
        "id": "7KOHEyKgP5oR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VISUALIZZAZIONE CON TP / FP / FN COLORATI"
      ],
      "metadata": {
        "id": "qk2jWMkdKEd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualizza_risultati(test_image, test_annot, clf)"
      ],
      "metadata": {
        "id": "5UaM-3YXKGrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VALUTAZIONE QUANTITATIVA SU TUTTE LE IMMAGINI DI TEST"
      ],
      "metadata": {
        "id": "K4-yrorWKJkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esegui la valutazione su tutto il test set\n",
        "evaluate_batch(\"/content/test_images\", \"/content/test_annotations\", clf)"
      ],
      "metadata": {
        "id": "IvMgAGQzKOKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusione\n",
        "\n",
        "Questa soluzione rispetta pienamente **tutti i vincoli** del progetto e dimostra:\n",
        "\n",
        "- CapacitÃ  di progettare una pipeline completa da zero\n",
        "- Utilizzo efficace di tecniche classiche di Computer Vision\n",
        "- Attenzione allâ€™ottimizzazione per risorse limitate\n",
        "- Competenze nella raccolta dati, addestramento, valutazione e documentazione\n",
        "\n",
        "Inoltre, lâ€™intera soluzione Ã¨ **riproducibile**, **trasparente** e facilmente estendibile a sistemi embedded o real-time in ambienti con capacitÃ  limitate."
      ],
      "metadata": {
        "id": "pKK3l8s0P_L8"
      }
    }
  ]
}